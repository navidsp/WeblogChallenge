{"cells":[{"cell_type":"markdown","source":["### 1- Loading the log file from S3"],"metadata":{}},{"cell_type":"code","source":["ACCESS_KEY = \"*\"\nSECRET_KEY = \"*\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"*\"\nMOUNT_NAME = \"*\"\n\ndbutils.fs.unmount(\"/mnt/%s\" % MOUNT_NAME)\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n\nlog_file_path = \"/mnt/%s/2015_07_22_mktplace_shop_web_log_sample.log\" % MOUNT_NAME\nbase_df = sqlContext.read.text(log_file_path)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["## 2- Parsing the log file"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_extract\n\n# 2015-07-22T09:02:24.432545Z marketpalce-shop 203.115.101.197:14413 10.0.6.99:80 0.000022 0.095994 0.000019 200 200 0 1574 \"GET https://paytm.com:443/shop/cart?channel=web&version=2 HTTP/1.1\" \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\" ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2\n\nsplit_df = base_df.select(regexp_extract('value', r'^([^\\s]*).*', 1).cast('timestamp').alias('timestamp'),\n                          #regexp_extract('value', r'^([^\\s]*).*', 1).cast('timestamp').cast('long').alias('timestamp_long'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s)([^\\s]*).*', 1).alias('elb'),\n                          regexp_extract('value', r'^(?:[^\\s]*\\s){2}([^\\s]*):.*', 1).alias('client_ip'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){2}[^\\s]*:(\\d*).*', 1).alias('client_port'),\n                          regexp_extract('value', r'^(?:[^\\s]*\\s){3}([^\\s]*).*', 1).alias('backend_address'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){4}([^\\s]*).*', 1).alias('request_processing_time'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){5}([^\\s]*).*', 1).alias('backend_processing_time'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){6}([^\\s]*).*', 1).alias('response_processing_time'),\n                          regexp_extract('value', r'^(?:[^\\s]*\\s){7}([^\\s]*).*', 1).alias('elb_status_code'),\n                          regexp_extract('value', r'^(?:[^\\s]*\\s){8}([^\\s]*).*', 1).alias('backend_status_code'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){9}([^\\s]*).*', 1).alias('received_bytes'),\n                          #regexp_extract('value', r'^(?:[^\\s]*\\s){10}([^\\s]*).*', 1).alias('sent_bytes'),\n                          #regexp_extract('value', r'^[^\"]*\\s\"([^\"]*)\".*', 1).alias('request'),\n                          regexp_extract('value', r'^[^\"]*\\s\"[^\"]*\\s([^\"]*)\\s[^\"]*\".*', 1).alias('request_address'),\n                          regexp_extract('value', r'^.*\\s\"(.*)\".*', 1).alias('user_agent'),\n                          #regexp_extract('value', r'^.*\"\\s(.*)\\s.*', 1).alias('ssl_cipher'),\n                          #regexp_extract('value', r'^.*\\s(.*)$', 1).alias('ssl_protocol')\n                         )\n\nsplit_df.cache()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["## 3- Data Exploration"],"metadata":{}},{"cell_type":"markdown","source":["- Noticed there are 164 records with '-' `backend_address`:  \n`split_df.groupby('backend_address').count().collect()`  \n  \n- Turned out `backend_address` will be '-', if there is a 504 (Gateway timeout) error.\n`split_df.filter(split_df['backend_address'] == '-').groupBy(['elb_status_code','backend_status_code']).count().collect()`\n\n- Approximatly %7.6 of the traffic is coming from 3 IP addresses  \n`(split_df.groupby('client_ip', 'user_agent').count().sort('count', ascending = False)).show(10, False)`    \n - 52.74.219.71 : 40633 - This is Google bot since the `user_agent` has google bot keyword  \n - 119.81.61.166 : 32829 - Not clear what is this IP\n - 106.186.23.95 : 14565 - Seems to be a service for checking promotions since it usually calls the `promotion` API: `cleanedup_sessionized_df.filter(cleanedup_sessionized_df['client_ip'] == '106.186.23.95').show(100, truncate = False)`"],"metadata":{}},{"cell_type":"markdown","source":["## 4- Processing and analytical goals"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.window import Window\nfrom pyspark.sql.functions import lag, when, sum, concat, avg, countDistinct, lit\nimport sys\n\n# Setting the threshold to 15 minutes\ninactivity_threshold = 15 * 60\n\nwindow = Window.partitionBy('client_ip').orderBy('timestamp')\n\n# Adding a new column to check the inactivity time between the current row and the previous row (rows are ordered by timestamp)\nseconds_since_last_activity = split_df['timestamp'].cast('long') - lag(split_df['timestamp'].cast('long'), default = 0).over(window)\n\n# Adding a new column to check if the inactivity time is greater than the threshold\nis_new_session = when(seconds_since_last_activity > inactivity_threshold, 1).otherwise(0)\n\n# Building the session_id\nsession_id = \\\n  concat(split_df['client_ip'], \\\n         lit('::'), \\\n         (sum(is_new_session).over(window.rowsBetween(-sys.maxsize, 0))).cast('string'))\n\nsessionized_df = \\\n  split_df \\\n    .select('*', \\\n            seconds_since_last_activity.alias('seconds_since_last_activity'), \\\n            is_new_session.alias('is_new_session'), \\\n            session_id.alias('session_id'))\n\nlast_activity = when(sessionized_df['is_new_session'] == 1, 0).otherwise(sessionized_df['seconds_since_last_activity'])\n\n# Sessionizing the records\ncleanedup_sessionized_df = sessionized_df \\\n                            .select('*',\n                                    last_activity.alias('last_activity'))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Create a new data frame with session id and session time\nsession_time_df = cleanedup_sessionized_df.select('*').groupBy('session_id').agg(sum('last_activity').alias('session_time'))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Average session time\naverage_session_time = session_time_df.select(avg(session_time_df['session_time'])).collect()\nprint 'Average Session Time (seconds): %.4f' % average_session_time[0][0]"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Determine unique URL visits per session. To clarify, count a hit to a unique URL only once per session.\ncleanedup_sessionized_df \\\n  .select('*') \\\n  .groupBy('session_id') \\\n  .agg(cleanedup_sessionized_df['session_id'], countDistinct(cleanedup_sessionized_df['request_address'])) \\\n  .show(20, truncate = False)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Most engaged users\nsession_time_df.select('*').orderBy('session_time', ascending = False).collect()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"paytm_ WeblogChallenge","notebookId":1727772549406828},"nbformat":4,"nbformat_minor":0}
